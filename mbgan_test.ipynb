{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a4a359-d257-480f-bbaa-27b3ad909268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MBGAN.py and utils.py functions\n",
    "from MBGAN import MBGAN\n",
    "from scipy.stats import describe\n",
    "from utils import *\n",
    "\n",
    "# disable eager execution\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d47ba8-db83-481b-a59e-0510d6fd155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the GAN and its output directory, specify data file name, num. epochs, batch size, and save interval\n",
    "NAME = \"mbgan\"\n",
    "EXP_DIR = \"mbgan_test\"\n",
    "FILE = \"raw_data.pkl\"\n",
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 32\n",
    "SAVE_INTERVAL = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73e7ecd-7c8b-45d7-b823-82fbea25cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for saving GAN output\n",
    "def get_save_fn(taxa_list):\n",
    "    \n",
    "    def fn(model, epoch):\n",
    "        # make a directory for output tables\n",
    "        table_dir = os.path.join(model.log_dir, \"tables\")\n",
    "        if not os.path.exists(table_dir):\n",
    "            os.makedirs(table_dir)\n",
    "        \n",
    "        #create 1000 samples and measure sparsity and entropy\n",
    "        res = model.predict(1000, transform=None, seed=None)\n",
    "        sparsity, entropy = get_sparsity(res), shannon_entropy(res)\n",
    "        print(\"sparsity: %s\" % str(describe(sparsity)))\n",
    "        print(\"entropy: %s\" % str(describe(entropy)))\n",
    "        \n",
    "        # name output file\n",
    "        filename = \"{:s}_{:06d}--{:.4f}--{:.4f}.csv\".format(\n",
    "            model.model_name, epoch, np.mean(sparsity), np.mean(entropy))\n",
    "        \n",
    "        # save output to csv\n",
    "        pd.DataFrame(res, columns=taxa_list).to_csv(os.path.join(table_dir, filename))\n",
    "        \n",
    "        return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "055f81ca-1125-4a58-a9ee-fde540363c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from .pkl or .csv - function changes depending on file format\n",
    "data_o_case, data_o_ctrl, taxa_list = load_sample_pickle_data(FILE)\n",
    "\n",
    "# use expand_phylo function from utils.py to create adj matrix and taxa indices\n",
    "adj_matrix, taxa_indices = expand_phylo(taxa_list)\n",
    "\n",
    "# convert adj matrix to dense\n",
    "tf_matrix = adjmatrix_to_dense(adj_matrix, shape=(len(taxa_list), len(taxa_indices)))\n",
    "    \n",
    "#specify model configurations\n",
    "model_config = {\n",
    "        'ntaxa': 719, #num. taxa\n",
    "        'latent_dim': 100, #z_dim\n",
    "        'generator': {'n_channels': 512}, #num. channels in each generator layer\n",
    "        'critic': {'n_channels': 256, 'dropout_rate': 0.25, \n",
    "                   'tf_matrix': tf_matrix, 't_pow': 1000.} #num. channels, dropout, phylogenetic matrix, and scale for critic\n",
    "    }\n",
    "    \n",
    "# specify training configuration\n",
    "train_config = {\n",
    "        'generator': {'optimizer': ('RMSprop', {}), 'lr': 0.00005}, #specify generator optimizer + learning_rate\n",
    "        'critic': {'loss_weights': [1, 1, 10],\n",
    "                   'optimizer': ('RMSprop', {}), 'lr': 0.00005}, #specify critic loss weights, optimizer, and learning rate\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042e86a-c382-4b74-8859-d03f457430a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b4f9f0-c53c-47fe-b29e-ca1e658a73c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated Sample Shape: Tensor(\"random_weighted_average/add:0\", shape=(None, 719), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#instantiate model\n",
    "mbgan = MBGAN(NAME, model_config, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c72334d-2a85-4f05-aa17-4dc29049240a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16532d6-f9f2-40bf-9f92-ea0a24145131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################\n",
      "Training start at: 2022-04-12 13:35:16\n",
      "Run MB-GAN for 10000 iterations with batch_size=32\n",
      "Save generated samples and model every 1000 iters\n",
      "Results are exported to folder: mbgan_test\\mbgan_20220412T133516\n",
      "    Create log folder: mbgan_test\\mbgan_20220412T133516\n",
      "    Create model folder: mbgan_test\\mbgan_20220412T133516\\models\n",
      "Generator structure:\n",
      "Model: \"generator_graph\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "noise (InputLayer)           [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "generator (Functional)       (None, 719)               952015    \n",
      "_________________________________________________________________\n",
      "critic (Functional)          (None, 1)                 449281    \n",
      "=================================================================\n",
      "Total params: 1,401,296\n",
      "Trainable params: 948,943\n",
      "Non-trainable params: 452,353\n",
      "_________________________________________________________________\n",
      "Critic structure:\n",
      "Model: \"critic_graph\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "noise (InputLayer)              [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "real_sample (InputLayer)        [(None, 719)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator (Functional)          (None, 719)          952015      noise[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "random_weighted_average (Random (None, 719)          0           real_sample[0][0]                \n",
      "                                                                 generator[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "critic (Functional)             (None, 1)            449281      generator[0][0]                  \n",
      "                                                                 real_sample[0][0]                \n",
      "                                                                 random_weighted_average[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 901,634\n",
      "Trainable params: 449,281\n",
      "Non-trainable params: 452,353\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "iter=1 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=2 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=3 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=4 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=5 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=6 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=7 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=8 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=9 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=10 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=11 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=12 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=13 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=14 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=15 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=16 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=17 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=18 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=19 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=20 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=21 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=22 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=23 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=24 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=25 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=26 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=27 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=28 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=29 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=30 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=31 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=32 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=33 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=34 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=35 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=36 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=37 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=38 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=39 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=40 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=41 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=42 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=43 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=44 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=45 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=46 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=47 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=48 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=49 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=50 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=51 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=52 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=53 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=54 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=55 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=56 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=57 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=58 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=59 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=60 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=61 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=62 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=63 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=64 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=65 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=66 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=67 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=68 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=69 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=70 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=71 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=72 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=73 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=74 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=75 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=76 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=77 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=78 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=79 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=80 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=81 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=82 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=83 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=84 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=85 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=86 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=87 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=88 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=89 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=90 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=91 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=92 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=93 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=94 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=95 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=96 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=97 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=98 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=99 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=100 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=101 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=102 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=103 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=104 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=105 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=106 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=107 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=108 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=109 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=110 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=111 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=112 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=113 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=114 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=115 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=116 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=117 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=118 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=119 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=120 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=121 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=122 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=123 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=124 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=125 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=126 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=127 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=128 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=129 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=130 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=131 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=132 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=133 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=134 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=135 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=136 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=137 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=138 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=139 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=140 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=141 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=142 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=143 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=144 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=145 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=146 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=147 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=148 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=149 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=150 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=151 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=152 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=153 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=154 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=155 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=156 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=157 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=158 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=159 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=160 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=161 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=162 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=163 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=164 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=165 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=166 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=167 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=168 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=169 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=170 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=171 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=172 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=173 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=174 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=175 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=176 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=177 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=178 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=179 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=180 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=181 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=182 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=183 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=184 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=185 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=186 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=187 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=188 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=189 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=190 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=191 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=192 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=193 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=194 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=195 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=196 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=197 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=198 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=199 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=200 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=201 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=202 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=203 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=204 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=205 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=206 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=207 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=208 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=209 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=210 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=211 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=212 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=213 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=214 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=215 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=216 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=217 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=218 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=219 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=220 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=221 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=222 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=223 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=224 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=225 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=226 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=227 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=228 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=229 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=230 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=231 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=232 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=233 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=234 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=235 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=236 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=237 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=238 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=239 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=240 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=241 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=242 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=243 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=244 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=245 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=246 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=247 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=248 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=249 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=250 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=251 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=252 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=253 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=254 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=255 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=256 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=257 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=258 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=259 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=260 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=261 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=262 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=263 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=264 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=265 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=266 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=267 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=268 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=269 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=270 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=271 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=272 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=273 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=274 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=275 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=276 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=277 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=278 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=279 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=280 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=281 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=282 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=283 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=284 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=285 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=286 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=287 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=288 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=289 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=290 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=291 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=292 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=293 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=294 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=295 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=296 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=297 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=298 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=299 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=300 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=301 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=302 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=303 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=304 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=305 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=306 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=307 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=308 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=309 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=310 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=311 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=312 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=313 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=314 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=315 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=316 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=317 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=318 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=319 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=320 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=321 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=322 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=323 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=324 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=325 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=326 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=327 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=328 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=329 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=330 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=331 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=332 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=333 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=334 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=335 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=336 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=337 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=338 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=339 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=340 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=341 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=342 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=343 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=344 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=345 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=346 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=347 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=348 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=349 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=350 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=351 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=352 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=353 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=354 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=355 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=356 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=357 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=358 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=359 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=360 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=361 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=362 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=363 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=364 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=365 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=366 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=367 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=368 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=369 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=370 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=371 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=372 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=373 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=374 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=375 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=376 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=377 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=378 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=379 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=380 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=381 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=382 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=383 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=384 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=385 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=386 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=387 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=388 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=389 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=390 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=391 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=392 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=393 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=394 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=395 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=396 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=397 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=398 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=399 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=400 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=401 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=402 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=403 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=404 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=405 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=406 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=407 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=408 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=409 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=410 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=411 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=412 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=413 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=414 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=415 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=416 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=417 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=418 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=419 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=420 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=421 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=422 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=423 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=424 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=425 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=426 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=427 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=428 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=429 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=430 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=431 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=432 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=433 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=434 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=435 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=436 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=437 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=438 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=439 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=440 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=441 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=442 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=443 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=444 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=445 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=446 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=447 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=448 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=449 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=450 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=451 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=452 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=453 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=454 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=455 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=456 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=457 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=458 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=459 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=460 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=461 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=462 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=463 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=464 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=465 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=466 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=467 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=468 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=469 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=470 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=471 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=472 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=473 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=474 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=475 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=476 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=477 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=478 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=479 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=480 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=481 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=482 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=483 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=484 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=485 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=486 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=487 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=488 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=489 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=490 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=491 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=492 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=493 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=494 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=495 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=496 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=497 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=498 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=499 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=500 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=501 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=502 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=503 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=504 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=505 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=506 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=507 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=508 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=509 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=510 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=511 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=512 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=513 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=514 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=515 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=516 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=517 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=518 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=519 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=520 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=521 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=522 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=523 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=524 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=525 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=526 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=527 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=528 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=529 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=530 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=531 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=532 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=533 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=534 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=535 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=536 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=537 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=538 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=539 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=540 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=541 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=542 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=543 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=544 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=545 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=546 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n",
      "iter=547 [D loss=nan, w_loss_real=nan, w_loss_fake=nan, gp_loss=nan] [G loss=nan]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19844/2507195802.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m mbgan.train(data_o_case, iteration=EPOCHS, batch_size=BATCH_SIZE,\n\u001b[0m\u001b[0;32m      3\u001b[0m             \u001b[0mn_critic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_generator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_save_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtaxa_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0msave_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSAVE_INTERVAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEXP_DIR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             pre_processor=None, verbose=0)\n",
      "\u001b[1;32m~\\CSI Research\\MBGAN.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, dataset, iteration, batch_size, n_critic, n_generator, save_interval, save_fn, experiment_dir, pre_processor, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m                     \u001b[0mreal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_processor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m                 \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_training_eval_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m       \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m     \u001b[1;31m# Reset metrics on all the distributed (cloned) models.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   3729\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3730\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3731\u001b[1;33m         \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1369\u001b[0m                            run_metadata)\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1373\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1360\u001b[0m                                       target_list, run_metadata)\n\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1449\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1450\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1451\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m                                             run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "mbgan.train(data_o_case, iteration=EPOCHS, batch_size=BATCH_SIZE,\n",
    "            n_critic=5, n_generator=1, save_fn=get_save_fn(taxa_list),\n",
    "            save_interval=SAVE_INTERVAL, experiment_dir=EXP_DIR,\n",
    "            pre_processor=None, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
